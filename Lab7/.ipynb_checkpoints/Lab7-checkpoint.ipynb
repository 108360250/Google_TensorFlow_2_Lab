{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51645b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from preprocessing import parse_aug_fn, parse_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa241bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0]\n",
      " [0 2 1]\n",
      " [1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "y_true = [2, 1, 0, 2, 2, 0, 1, 1]\n",
    "y_pred = [0, 1, 0, 2, 2, 0, 2, 1]\n",
    "cm = tf.math.confusion_matrix(y_true, y_pred, num_classes=3).numpy()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26414b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    產生一張圖表示的Confusion matrix\n",
    "    \n",
    "    Args:\n",
    "    cm (shape = [n, n]): 傳入Confusion matrix\n",
    "    class_names (shape = [n]): 傳入類別\n",
    "    \"\"\"\n",
    "    # 標準化confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    tick_index = np.arange(len(class_names))\n",
    "    # matplotlib 3.1.1 bug，如果不設定ylim在[-0.5~2.5]，圖片y軸範圍會被縮小成[0~2]\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "    # Y軸顯示類別名稱\n",
    "    plt.yticks(tick_index, class_names)\n",
    "    # X軸顯示類別名稱，並將類別名稱旋轉45度(避免文字重疊)\n",
    "    plt.xticks(tick_index, class_names, rotation=45)\n",
    "    # 再圖片右邊產生一條顏色刻度條\n",
    "    plt.colorbar()\n",
    "\n",
    "    # 在每一格Confusion matrix輸入預測百分比\n",
    "    threshold = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            # 如果格內背景顏色太深使用白色文字顯示，反之使用黑色文字\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "            \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    # 將圖片的位置進行調整，避免x或y軸的文字被遮擋\n",
    "    plt.tight_layout()\n",
    "    return figure\n",
    "\n",
    "# Example\n",
    "img = plot_confusion_matrix(cm, [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba66b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"將Matplotlib plot的圖片轉TensorFlow的張量格式\"\"\"\n",
    "    # 將Matplotlib plot的圖片以PNG的格式儲存到記憶體中\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # 關閉plt圖片，防止圖片直接顯示在Jupyter notebook介面中\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # 將記憶體中的資料轉成TensorFlow格式\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eebf7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "y_true = [2, 0, 2, 2, 0, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2]\n",
    "cm = tf.math.confusion_matrix(y_true, y_pred, num_classes=3).numpy()\n",
    "img = plot_confusion_matrix(cm, [0, 1, 2])\n",
    "img_show = plot_to_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b38bd28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, log_dir, test_data, class_name):\n",
    "        super(ConfusionMatrix, self).__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.test_data = test_data\n",
    "        self.class_names = class_name\n",
    "        self.num_classes = len(class_name)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        path = os.path.join(self.log_dir, 'confusion_matrix')\n",
    "        # 創建TensorBoard紀錄檔\n",
    "        self.writer = tf.summary.create_file_writer(path)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # 計算Confusion matrix\n",
    "        total_cm = np.zeros([10, 10])\n",
    "        for x, y_true in self.test_data:\n",
    "            y_pred = self.model.predict(x)\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "            cm = tf.math.confusion_matrix(y_true, y_pred, num_classes=self.num_classes).numpy()\n",
    "            total_cm += cm\n",
    "        \n",
    "        # 將Confusion matrix轉成Matplotlib圖片\n",
    "        figure = plot_confusion_matrix(total_cm, class_names=self.class_names)\n",
    "        # 將Matplotlib圖片轉成TensorFlow型式的圖片\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # 將圖片紀錄在TensorBoard log中\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e148d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將train Data重新分成9:1等分，分別分給train data, valid data\n",
    "train_split, valid_split = ['train[:90%]', 'train[90%:]']\n",
    "# 取得訓練數據，並順便讀取data的資訊\n",
    "train_data, info = tfds.load(\"cifar10\", split=train_split, with_info=True)\n",
    "# 取得驗證數據\n",
    "valid_data = tfds.load(\"cifar10\", split=valid_split)\n",
    "# 取得測試數據\n",
    "test_data = tfds.load(\"cifar10\", split=tfds.Split.TEST)\n",
    "# 取得CIFAR-10數據集的類別\n",
    "class_name = info.features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c39f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE  # 自動調整模式\n",
    "batch_size = 64  # 批次大小\n",
    "train_num = int(info.splits['train'].num_examples / 10) * 9  # 訓練資料數量\n",
    "\n",
    "train_data = train_data.shuffle(train_num)  # 打散資料集\n",
    "# 載入預處理「 parse_aug_fn」function，cpu數量為自動調整模式\n",
    "train_data = train_data.map(map_func=parse_aug_fn, num_parallel_calls=AUTOTUNE)\n",
    "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
    "train_data = train_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
    "valid_data = valid_data.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
    "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
    "valid_data = valid_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
    "test_data = test_data.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
    "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
    "test_data = test_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2923f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model-1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 128)         295040    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 64)          73792     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 941,066\n",
      "Trainable params: 941,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(64, 3, activation='relu', kernel_initializer='glorot_uniform')(inputs)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "# 建立網路模型(將輸入到輸出所有經過的網路層連接起來)\n",
    "model_1 = keras.Model(inputs, outputs, name='model-1')\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6774193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存訓練記錄檔\n",
    "logs_dirs = 'lab7-logs-images'\n",
    "model_cbk = keras.callbacks.TensorBoard(logs_dirs)\n",
    "# 儲存Confusion matrix圖片\n",
    "save_cm = ConfusionMatrix(logs_dirs, test_data, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a54134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(keras.optimizers.Adam(), \n",
    "                loss=keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                metrics=[keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e8c34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  6/704 [..............................] - ETA: 1:02 - loss: 2.3115 - categorical_accuracy: 0.1120WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0101s vs `on_train_batch_end` time: 0.0665s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0101s vs `on_train_batch_end` time: 0.0665s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 27s 20ms/step - loss: 2.1048 - categorical_accuracy: 0.1911 - val_loss: 1.8739 - val_categorical_accuracy: 0.3134\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.9776 - categorical_accuracy: 0.2470 - val_loss: 1.8446 - val_categorical_accuracy: 0.3356oss: 1.9839 - categorica - ETA: 1s - loss: - ETA: 0s - loss: 1.9785 - categorical_\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.8748 - categorical_accuracy: 0.3073 - val_loss: 1.6121 - val_categorical_accuracy: 0.4140\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.7383 - categorical_accuracy: 0.3660 - val_loss: 1.3785 - val_categorical_accuracy: 0.5128\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.6464 - categorical_accuracy: 0.4083 - val_loss: 1.3163 - val_categorical_accuracy: 0.5202\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.5621 - categorical_accuracy: 0.4361 - val_loss: 1.1957 - val_categorical_accuracy: 0.5718\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.5180 - categorical_accuracy: 0.4612 - val_loss: 1.1828 - val_categorical_accuracy: 0.5818\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.4605 - categorical_accuracy: 0.4801 - val_loss: 1.1279 - val_categorical_accuracy: 0.60560.48\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.4187 - categorical_accuracy: 0.4962 - val_loss: 1.0952 - val_categorical_accuracy: 0.6024\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.3925 - categorical_accuracy: 0.5112 - val_loss: 1.0482 - val_categorical_accuracy: 0.63923 - categorical_accura\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.3569 - categorical_accuracy: 0.5270 - val_loss: 1.0215 - val_categorical_accuracy: 0.6382\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.3262 - categorical_accuracy: 0.5373 - val_loss: 1.0888 - val_categorical_accuracy: 0.6232\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.3017 - categorical_accuracy: 0.5486 - val_loss: 0.9474 - val_categorical_accuracy: 0.6682\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.2872 - categorical_accuracy: 0.5540 - val_loss: 0.9181 - val_categorical_accuracy: 0.6802\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.2478 - categorical_accuracy: 0.5672 - val_loss: 0.9458 - val_categorical_accuracy: 0.6588\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 1.2367 - categorical_accuracy: 0.5728 - val_loss: 0.8881 - val_categorical_accuracy: 0.6778\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.2109 - categorical_accuracy: 0.5805 - val_loss: 0.8898 - val_categorical_accuracy: 0.6858\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.1935 - categorical_accuracy: 0.5892 - val_loss: 0.9475 - val_categorical_accuracy: 0.6662\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.1804 - categorical_accuracy: 0.5947 - val_loss: 0.8736 - val_categorical_accuracy: 0.6914\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.1585 - categorical_accuracy: 0.6006 - val_loss: 0.8472 - val_categorical_accuracy: 0.7080\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.1510 - categorical_accuracy: 0.6077 - val_loss: 0.8250 - val_categorical_accuracy: 0.7118\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.1341 - categorical_accuracy: 0.6105 - val_loss: 0.8324 - val_categorical_accuracy: 0.7052\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.1170 - categorical_accuracy: 0.6187 - val_loss: 0.8179 - val_categorical_accuracy: 0.7154\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.1047 - categorical_accuracy: 0.6195 - val_loss: 0.8022 - val_categorical_accuracy: 0.7138\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0961 - categorical_accuracy: 0.6262 - val_loss: 0.7820 - val_categorical_accuracy: 0.7346: 0s - loss: 1.0959 - categorical_accu\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0851 - categorical_accuracy: 0.6291 - val_loss: 0.8027 - val_categorical_accuracy: 0.7174\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0715 - categorical_accuracy: 0.6366 - val_loss: 0.7825 - val_categorical_accuracy: 0.7234\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0599 - categorical_accuracy: 0.6393 - val_loss: 0.7920 - val_categorical_accuracy: 0.7362\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0542 - categorical_accuracy: 0.6387 - val_loss: 0.7493 - val_categorical_accuracy: 0.7376\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0460 - categorical_accuracy: 0.6431 - val_loss: 0.7500 - val_categorical_accuracy: 0.7386\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0386 - categorical_accuracy: 0.6458 - val_loss: 0.7271 - val_categorical_accuracy: 0.7346\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0280 - categorical_accuracy: 0.6519 - val_loss: 0.8034 - val_categorical_accuracy: 0.7244\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0175 - categorical_accuracy: 0.6534 - val_loss: 0.7381 - val_categorical_accuracy: 0.7404\n",
      "Epoch 34/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0099 - categorical_accuracy: 0.6530 - val_loss: 0.7987 - val_categorical_accuracy: 0.7310\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0056 - categorical_accuracy: 0.6562 - val_loss: 0.7908 - val_categorical_accuracy: 0.7244\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 1.0017 - categorical_accuracy: 0.6634 - val_loss: 0.7304 - val_categorical_accuracy: 0.7490ca\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9905 - categorical_accuracy: 0.6673 - val_loss: 0.7307 - val_categorical_accuracy: 0.7494\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9826 - categorical_accuracy: 0.6712 - val_loss: 0.7320 - val_categorical_accuracy: 0.7466\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9714 - categorical_accuracy: 0.6704 - val_loss: 0.7103 - val_categorical_accuracy: 0.7574\n",
      "Epoch 40/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9706 - categorical_accuracy: 0.6706 - val_loss: 0.6653 - val_categorical_accuracy: 0.7706\n",
      "Epoch 41/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9603 - categorical_accuracy: 0.6760 - val_loss: 0.7095 - val_categorical_accuracy: 0.7570\n",
      "Epoch 42/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9550 - categorical_accuracy: 0.6754 - val_loss: 0.7065 - val_categorical_accuracy: 0.7606\n",
      "Epoch 43/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9471 - categorical_accuracy: 0.6763 - val_loss: 0.7161 - val_categorical_accuracy: 0.7598\n",
      "Epoch 44/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9430 - categorical_accuracy: 0.6789 - val_loss: 0.7057 - val_categorical_accuracy: 0.7586\n",
      "Epoch 45/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9388 - categorical_accuracy: 0.6825 - val_loss: 0.7351 - val_categorical_accuracy: 0.7510\n",
      "Epoch 46/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9279 - categorical_accuracy: 0.6858 - val_loss: 0.6935 - val_categorical_accuracy: 0.7616\n",
      "Epoch 47/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9285 - categorical_accuracy: 0.6885 - val_loss: 0.6987 - val_categorical_accuracy: 0.7606\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9227 - categorical_accuracy: 0.6888 - val_loss: 0.6859 - val_categorical_accuracy: 0.7686\n",
      "Epoch 49/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9197 - categorical_accuracy: 0.6880 - val_loss: 0.6676 - val_categorical_accuracy: 0.7668\n",
      "Epoch 50/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9148 - categorical_accuracy: 0.6908 - val_loss: 0.6674 - val_categorical_accuracy: 0.7720\n",
      "Epoch 51/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9168 - categorical_accuracy: 0.6898 - val_loss: 0.6948 - val_categorical_accuracy: 0.7624\n",
      "Epoch 52/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9044 - categorical_accuracy: 0.6955 - val_loss: 0.6838 - val_categorical_accuracy: 0.7644\n",
      "Epoch 53/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8979 - categorical_accuracy: 0.6988 - val_loss: 0.7257 - val_categorical_accuracy: 0.7610\n",
      "Epoch 54/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.9002 - categorical_accuracy: 0.6973 - val_loss: 0.6637 - val_categorical_accuracy: 0.7704\n",
      "Epoch 55/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8983 - categorical_accuracy: 0.7008 - val_loss: 0.6701 - val_categorical_accuracy: 0.7724\n",
      "Epoch 56/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8865 - categorical_accuracy: 0.7042 - val_loss: 0.6836 - val_categorical_accuracy: 0.7728\n",
      "Epoch 57/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8749 - categorical_accuracy: 0.7086 - val_loss: 0.6641 - val_categorical_accuracy: 0.7724\n",
      "Epoch 58/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8911 - categorical_accuracy: 0.7029 - val_loss: 0.7136 - val_categorical_accuracy: 0.7670\n",
      "Epoch 59/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8830 - categorical_accuracy: 0.7046 - val_loss: 0.6788 - val_categorical_accuracy: 0.7756\n",
      "Epoch 60/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8785 - categorical_accuracy: 0.7084 - val_loss: 0.6926 - val_categorical_accuracy: 0.7678\n",
      "Epoch 61/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8773 - categorical_accuracy: 0.7062 - val_loss: 0.6760 - val_categorical_accuracy: 0.7692\n",
      "Epoch 62/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8671 - categorical_accuracy: 0.7105 - val_loss: 0.6752 - val_categorical_accuracy: 0.7736\n",
      "Epoch 63/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8555 - categorical_accuracy: 0.7123 - val_loss: 0.6836 - val_categorical_accuracy: 0.7734\n",
      "Epoch 64/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8684 - categorical_accuracy: 0.7106 - val_loss: 0.6695 - val_categorical_accuracy: 0.7738\n",
      "Epoch 65/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.8618 - categorical_accuracy: 0.7112 - val_loss: 0.6765 - val_categorical_accuracy: 0.7788\n",
      "Epoch 66/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8671 - categorical_accuracy: 0.7106 - val_loss: 0.6616 - val_categorical_accuracy: 0.7816\n",
      "Epoch 67/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8477 - categorical_accuracy: 0.7181 - val_loss: 0.6672 - val_categorical_accuracy: 0.7734\n",
      "Epoch 68/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8458 - categorical_accuracy: 0.7162 - val_loss: 0.6828 - val_categorical_accuracy: 0.7750\n",
      "Epoch 69/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8391 - categorical_accuracy: 0.7199 - val_loss: 0.6723 - val_categorical_accuracy: 0.7800\n",
      "Epoch 70/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8434 - categorical_accuracy: 0.7180 - val_loss: 0.6600 - val_categorical_accuracy: 0.7766\n",
      "Epoch 71/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8336 - categorical_accuracy: 0.7245 - val_loss: 0.6773 - val_categorical_accuracy: 0.7674\n",
      "Epoch 72/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8397 - categorical_accuracy: 0.7222 - val_loss: 0.6205 - val_categorical_accuracy: 0.7904\n",
      "Epoch 73/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8311 - categorical_accuracy: 0.7213 - val_loss: 0.6435 - val_categorical_accuracy: 0.7788\n",
      "Epoch 74/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8356 - categorical_accuracy: 0.7209 - val_loss: 0.6641 - val_categorical_accuracy: 0.7798\n",
      "Epoch 75/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8223 - categorical_accuracy: 0.7264 - val_loss: 0.6553 - val_categorical_accuracy: 0.7802- categorical_ac - ETA: 0s - loss: 0.8228 - categorical_accuracy: 0. - ETA: 0s - loss: 0.8222 - categorical_accuracy: 0.\n",
      "Epoch 76/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8193 - categorical_accuracy: 0.7274 - val_loss: 0.6670 - val_categorical_accuracy: 0.7802\n",
      "Epoch 77/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8254 - categorical_accuracy: 0.7260 - val_loss: 0.6519 - val_categorical_accuracy: 0.7856\n",
      "Epoch 78/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8239 - categorical_accuracy: 0.7241 - val_loss: 0.6288 - val_categorical_accuracy: 0.7908\n",
      "Epoch 79/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8098 - categorical_accuracy: 0.7326 - val_loss: 0.6379 - val_categorical_accuracy: 0.7860\n",
      "Epoch 80/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8104 - categorical_accuracy: 0.7311 - val_loss: 0.6337 - val_categorical_accuracy: 0.7894\n",
      "Epoch 81/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8114 - categorical_accuracy: 0.7307 - val_loss: 0.6555 - val_categorical_accuracy: 0.7872\n",
      "Epoch 82/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8133 - categorical_accuracy: 0.7309 - val_loss: 0.6541 - val_categorical_accuracy: 0.7908\n",
      "Epoch 83/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8079 - categorical_accuracy: 0.7318 - val_loss: 0.6329 - val_categorical_accuracy: 0.7874tegorical_ac - ETA: 1s - loss: 0.8040 -  - ETA: 0s - loss: 0.8072 - categorical_ac - ETA: 0s - loss: 0.8070 - categorical_accuracy: 0.\n",
      "Epoch 84/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8019 - categorical_accuracy: 0.7356 - val_loss: 0.6271 - val_categorical_accuracy: 0.7890\n",
      "Epoch 85/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.7996 - categorical_accuracy: 0.7332 - val_loss: 0.6916 - val_categorical_accuracy: 0.7776\n",
      "Epoch 86/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.7995 - categorical_accuracy: 0.7356 - val_loss: 0.6771 - val_categorical_accuracy: 0.7746\n",
      "Epoch 87/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.8044 - categorical_accuracy: 0.7313 - val_loss: 0.6531 - val_categorical_accuracy: 0.7876\n",
      "Epoch 88/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.7972 - categorical_accuracy: 0.7347 - val_loss: 0.6166 - val_categorical_accuracy: 0.7956\n",
      "Epoch 89/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.7985 - categorical_accuracy: 0.7374 - val_loss: 0.6497 - val_categorical_accuracy: 0.7924\n",
      "Epoch 90/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.7916 - categorical_accuracy: 0.7394 - val_loss: 0.6383 - val_categorical_accuracy: 0.7914\n",
      "Epoch 91/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.7861 - categorical_accuracy: 0.7409 - val_loss: 0.6328 - val_categorical_accuracy: 0.7918\n",
      "Epoch 92/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.7912 - categorical_accuracy: 0.7363 - val_loss: 0.6353 - val_categorical_accuracy: 0.7882\n",
      "Epoch 93/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.7900 - categorical_accuracy: 0.7385 - val_loss: 0.6322 - val_categorical_accuracy: 0.7894\n",
      "Epoch 94/100\n",
      "704/704 [==============================] - 13s 19ms/step - loss: 0.7815 - categorical_accuracy: 0.7416 - val_loss: 0.6324 - val_categorical_accuracy: 0.7946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "704/704 [==============================] - 14s 19ms/step - loss: 0.7852 - categorical_accuracy: 0.7396 - val_loss: 0.6537 - val_categorical_accuracy: 0.7884\n",
      "Epoch 96/100\n",
      "704/704 [==============================] - 14s 19ms/step - loss: 0.7747 - categorical_accuracy: 0.7438 - val_loss: 0.6507 - val_categorical_accuracy: 0.7912\n",
      "Epoch 97/100\n",
      "704/704 [==============================] - 14s 19ms/step - loss: 0.7756 - categorical_accuracy: 0.7431 - val_loss: 0.6716 - val_categorical_accuracy: 0.7842\n",
      "Epoch 98/100\n",
      "704/704 [==============================] - 14s 19ms/step - loss: 0.7893 - categorical_accuracy: 0.7393 - val_loss: 0.7134 - val_categorical_accuracy: 0.7728\n",
      "Epoch 99/100\n",
      "704/704 [==============================] - 14s 19ms/step - loss: 0.7860 - categorical_accuracy: 0.7432 - val_loss: 0.6516 - val_categorical_accuracy: 0.7870\n",
      "Epoch 100/100\n",
      "704/704 [==============================] - 14s 19ms/step - loss: 0.7774 - categorical_accuracy: 0.7415 - val_loss: 0.6419 - val_categorical_accuracy: 0.7898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26c83613d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(train_data,\n",
    "            epochs=100, \n",
    "            validation_data=valid_data,\n",
    "            callbacks=[model_cbk, save_cm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bcab9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# 從資料夾中的preprocessing.py檔案中Import parse_aug_fn和parse_fn函數\n",
    "from preprocessing import parse_aug_fn, parse_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88bb0ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd762819",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparam_ia = hp.HParam('Imgae_Augmentation', hp.Discrete([False, True]))\n",
    "hparam_bn = hp.HParam('Batch_Normalization', hp.Discrete([False, True]))\n",
    "hparam_init = hp.HParam('Weight_Initialization', hp.Discrete(['RandomNormal_0.01std', 'glorot_normal', 'he_normal']))\n",
    "hparam_lr = hp.HParam('Learning_Rate', hp.Discrete([0.001, 0.01, 0.03]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdf48f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logs_dors = os.path.join('lab7-logs-hparams', 'hparam_tuning')\n",
    "#root_logdir_writer = tf.summary.create_file_writer(logs_dirs)\n",
    "#with root_logdir_writer.as_default ():\n",
    "#    hp.hparams_config(haparams=[hp_ia , hp_bn, hp_init, hp_lr], metrics=[hp_metric])\n",
    "\n",
    "metric = 'Accuracy'\n",
    "log_dirs = \"lab7-logs-hparams/hparam_tuning\"\n",
    "with tf.summary.create_file_writer(log_dirs).as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[hparam_ia, hparam_bn, hparam_init, hparam_lr],\n",
    "        metrics=[hp.Metric(metric, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "519179b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, valid_split = ['train[:90%]', 'train[90%:]']\n",
    "train_data_noaug, info = tfds.load(\"cifar10\", split=train_split,with_info=True)\n",
    "train_data_aug = tfds.load(\"cifar10\", split=train_split)\n",
    "valid_data = tfds.load(\"cifar10\", split=valid_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83bfd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE  # 自動調整模式\n",
    "batch_size = 64  # 批次大小\n",
    "# 將train Data重新分成1:9等分，分別分給valid data, train data\n",
    "train_split, valid_split = ['train[:90%]', 'train[90%:]']\n",
    "\n",
    "# 取得訓練數據\n",
    "train_data_noaug, info = tfds.load(\"cifar10\", split=train_split, with_info=True)\n",
    "train_data_aug = tfds.load(\"cifar10\", split=train_split)\n",
    "# 取得驗證數據\n",
    "valid_data = tfds.load(\"cifar10\", split=valid_split)\n",
    "\n",
    "train_num = int(info.splits['train'].num_examples / 5) * 4  # 訓練資料數量\n",
    "\n",
    "train_data_noaug = train_data_noaug.shuffle(train_num)  # 打散資料集\n",
    "# 載入預處理「 parse_aug_fn」function，cpu數量為自動調整模式\n",
    "train_data_noaug = train_data_noaug.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
    "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
    "train_data_noaug = train_data_noaug.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "train_data_aug = train_data_aug.shuffle(train_num)  # 打散資料集\n",
    "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
    "train_data_aug = train_data_aug.map(map_func=parse_aug_fn, num_parallel_calls=AUTOTUNE)\n",
    "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
    "train_data_aug = train_data_aug.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
    "valid_data = valid_data.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
    "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
    "valid_data = valid_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08fb4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparameterCallback(tf.keras.callbacks.Callback):\n",
    "    # 類別創建時調用\n",
    "    def __init__(self, log_dir, hparams):\n",
    "        super(HyperparameterCallback, self).__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.hparams = hparams\n",
    "        self.best_accuracy = 0\n",
    "        self.writer = None\n",
    "        \n",
    "    # 訓練開始前調用\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.writer = tf.summary.create_file_writer(self.log_dir)\n",
    "\n",
    "    # 每一個Epcoh結束後調用\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_accuracy = logs.get('val_categorical_accuracy')\n",
    "        if current_accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = current_accuracy\n",
    "            \n",
    "    # 訓練結束時調用\n",
    "    def on_train_end(self, logs=None):\n",
    "        with self.writer.as_default():\n",
    "            hp.hparams(self.hparams)  # record the values used in this trial\n",
    "            tf.summary.scalar(metric, self.best_accuracy, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e98f577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(logs_dir, hparams):\n",
    "    \"\"\"\n",
    "    logs_dir:傳入目前執行的任務log檔的位置\n",
    "    hparams:傳入超參數\n",
    "    \"\"\"\n",
    "    # 指派網路模型初始化的方法\n",
    "    if hparams[hparam_init] == \"glorot_normal\":\n",
    "        init = keras.initializers.glorot_normal()\n",
    "    elif hparams[hparam_init] == \"he_normal\":\n",
    "        init = keras.initializers.he_normal()\n",
    "    else:\n",
    "        init = keras.initializers.RandomNormal(0, 0.01)\n",
    "\n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    x = layers.Conv2D(64, (3, 3), kernel_initializer=init)(inputs)\n",
    "    if hparams[hparam_bn]: x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), kernel_initializer=init)(x)\n",
    "    if hparams[hparam_bn]: x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(256, (3, 3), kernel_initializer=init)(x)\n",
    "    if hparams[hparam_bn]: x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), kernel_initializer=init)(x)\n",
    "    if hparams[hparam_bn]: x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), kernel_initializer=init)(x)\n",
    "    if hparams[hparam_bn]: x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, kernel_initializer=init)(x)\n",
    "    if hparams[hparam_bn]: x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "    # 建立網路模型(將輸入到輸出所有經過的網路層連接起來)\n",
    "    model = keras.Model(inputs, outputs, name='model')\n",
    "\n",
    "    # 儲存訓練記錄檔\n",
    "    model_tb = keras.callbacks.TensorBoard(log_dir=logs_dir, write_graph=False)\n",
    "\n",
    "    # 儲存最好的網路模型權重\n",
    "    model_mckp = keras.callbacks.ModelCheckpoint(logs_dir +'/best-model.hdf5', \n",
    "                                                 monitor='val_categorical_accuracy', \n",
    "                                                 save_best_only=True, \n",
    "                                                 mode='max')\n",
    "    \n",
    "    # 設定停止訓練的條件(當Accuracy超過30迭代沒有上升的話訓練會終止)\n",
    "    model_els = keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy' , \n",
    "                                              min_delta=0, \n",
    "                                              patience=30, \n",
    "                                              mode='max')\n",
    "    # 客自化超參數回調函式，紀錄訓練模型的超參數和指標(準確率)\n",
    "    model_hparam = HyperparameterCallback(logs_dir + 'hparam_tuning', hparams)\n",
    "\n",
    "\n",
    "    # 設定訓練使用的優化器、損失函數和指標函數\n",
    "    # 優化器學習率為超參數：0.001、0.01或0.03\n",
    "    model.compile(keras.optimizers.Adam(hparams[hparam_lr]), \n",
    "                  loss=keras.losses.CategoricalCrossentropy(), \n",
    "                  metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    # 超參數：使用「經過影像增強的數據」或「不經過影像增強的數據」訓練網路\n",
    "    if hparams[hparam_ia]:\n",
    "        history = model.fit(train_data_aug,\n",
    "                            epochs=2, \n",
    "                            validation_data=valid_data,\n",
    "                            callbacks=[model_tb, model_mckp, model_els, model_hparam])\n",
    "    else:\n",
    "        history = model.fit(train_data_noaug,\n",
    "                            epochs=2, \n",
    "                            validation_data=valid_data,\n",
    "                            callbacks=[model_tb, model_mckp, model_els, model_hparam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe5d6b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running training session 1\n",
      "Epoch 1/2\n",
      "  6/704 [..............................] - ETA: 1:05 - loss: 2.3026 - categorical_accuracy: 0.0990WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0108s vs `on_train_batch_end` time: 0.0699s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0108s vs `on_train_batch_end` time: 0.0699s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 14s 19ms/step - loss: 2.3028 - categorical_accuracy: 0.0958 - val_loss: 2.3027 - val_categorical_accuracy: 0.0956\n",
      "Epoch 2/2\n",
      "704/704 [==============================] - 13s 18ms/step - loss: 2.3027 - categorical_accuracy: 0.0981 - val_loss: 2.3030 - val_categorical_accuracy: 0.0956\n",
      "--- Running training session 2\n",
      "Epoch 1/2\n",
      "  6/704 [..............................] - ETA: 50s - loss: 39.1023 - categorical_accuracy: 0.1146 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0532s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0532s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 14s 19ms/step - loss: 2.6178 - categorical_accuracy: 0.0997 - val_loss: 2.3045 - val_categorical_accuracy: 0.0940\n",
      "Epoch 2/2\n",
      "704/704 [==============================] - 13s 18ms/step - loss: 2.3034 - categorical_accuracy: 0.0996 - val_loss: 2.3046 - val_categorical_accuracy: 0.0940\n",
      "--- Running training session 3\n",
      "Epoch 1/2\n",
      "  6/704 [..............................] - ETA: 49s - loss: 98.6661 - categorical_accuracy: 0.1042  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0518s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0518s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 14s 19ms/step - loss: 3.1291 - categorical_accuracy: 0.0971 - val_loss: 2.3060 - val_categorical_accuracy: 0.0984\n",
      "Epoch 2/2\n",
      "704/704 [==============================] - 13s 18ms/step - loss: 2.3057 - categorical_accuracy: 0.0977 - val_loss: 2.3053 - val_categorical_accuracy: 0.0990\n",
      "--- Running training session 4\n",
      "Epoch 1/2\n",
      "  6/704 [..............................] - ETA: 1:05 - loss: 2.3131 - categorical_accuracy: 0.1094WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0710s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0710s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/704 [===>..........................] - ETA: 12s - loss: 2.1981 - categorical_accuracy: 0.1595"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13256/2980639135.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mlogs_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lab7-logs-hparams\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"run-{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[1;31m# 建立、編譯及訓練網路模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0mtrain_test_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[0msession_id\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# id+1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13256/1321987285.py\u001b[0m in \u001b[0;36mtrain_test_model\u001b[1;34m(logs_dir, hparams)\u001b[0m\n\u001b[0;32m     69\u001b[0m                             callbacks=[model_tb, model_mckp, model_els, model_hparam])\n\u001b[0;32m     70\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         history = model.fit(train_data_noaug,\n\u001b[0m\u001b[0;32m     72\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \"\"\"\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    513\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \"\"\"\n\u001b[0;32m   1093\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1094\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1095\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1058\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "session_id = 1  # 訓練任務的id\n",
    "for ia in hparam_ia.domain.values:\n",
    "    for bn in hparam_bn.domain.values:\n",
    "        for init in hparam_init.domain.values:\n",
    "            for lr in hparam_lr.domain.values:\n",
    "                # 顯示目前訓練任務id\n",
    "                print('--- Running training session {}'.format(session_id))\n",
    "                # 設定本次訓練的超參數\n",
    "                hparams = {hparam_ia: ia, hparam_bn: bn, hparam_init: init, hparam_lr: lr}\n",
    "                # 儲放紀錄檔的位置\n",
    "                logs_dir = os.path.join(\"lab7-logs-hparams\", \"run-{}\".format(session_id))\n",
    "                # 建立、編譯及訓練網路模型\n",
    "                train_test_model(logs_dir, hparams)\n",
    "                session_id += 1  # id+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69402efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3862df0183f8b19b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3862df0183f8b19b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 9875;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --port 9875 --logdir lab7-logs-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e19d2810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7d90f37c4b250894\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7d90f37c4b250894\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 9876;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --port 9876 --logdir lab7-logs-hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7ae3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
